{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6b960d-e5f9-4e93-8e6b-25295847fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "import random\n",
    "from typing import List\n",
    "from pandas.core.frame import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import phik\n",
    "from phik import resources, report\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790849b3-3535-42ad-a9e9-d5aa6a2c49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================DUPLICATES CHECK====================\n",
    "\n",
    "def duplicates_check(df: DataFrame, df_name: str) -> DataFrame:\n",
    "    \"\"\"Checks if there are any duplicated values in the dataframe and removes them.\n",
    "    Input: df(DataFrame), df_name(name of the DataFrame)\n",
    "    Returns: df\"\"\"\n",
    "    \n",
    "    print('-'*100)\n",
    "    print(f\"{df_name} had {df.shape[0]- df.drop_duplicates().shape[0]} rows removed\")\n",
    "    print('-'*100)\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "# ====================REDUCING MEMORY USAGE====================\n",
    "\n",
    "def reduce_memory_usage(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Reduced memory usage by downcasting datatype of columns.\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\"\"\"\n",
    "\n",
    "    for column in df:\n",
    "        if df[column].dtype == \"float64\":\n",
    "             df[column]=pd.to_numeric(df[column], downcast=\"float\")\n",
    "        if df[column].dtype == \"int64\":\n",
    "            df[column]=pd.to_numeric(df[column], downcast=\"integer\")\n",
    "    print(df.info())\n",
    "    return df\n",
    "\n",
    "# ====================TARGET DISTRIBUTION====================\n",
    "\n",
    "def pie_plot(df: DataFrame, col_name: str, labels: List) -> None:\n",
    "    \"\"\"Plots a pie chart of distribution of chosen column.\"\"\"\n",
    "    \n",
    "    # Data to plot\n",
    "    plot_data = df[col_name].value_counts() / df.shape[0]\n",
    "    \n",
    "    # Pie plot\n",
    "    plt.title(f\"Pie chart of {col_name} variable\")\n",
    "    plt.pie(plot_data, labels=labels, labeldistance=1.15, \n",
    "            wedgeprops= { 'linewidth' : 3, 'edgecolor' : 'white' }, autopct='%1.1f%%')\n",
    "    \n",
    "# ====================ASSIGN COLUMNS TO DATA TYPE====================\n",
    "\n",
    "def get_object_columns(df: DataFrame, target_name: str) -> List:\n",
    "    \"\"\"Gets all features which categorical features of object type from the dataset.\n",
    "    Parameters: df (DataFrame), target_name (name of the target column)\n",
    "    Returns: list of names of categorical columns of object type\"\"\"\n",
    "    \n",
    "    # Make a list\n",
    "    obj_col = df.select_dtypes(include='O').columns.to_list()\n",
    "    # Check if target column in list\n",
    "    if target_name in obj_col:\n",
    "        obj_col.remove(target_name)\n",
    "    # Return the list\n",
    "    return obj_col\n",
    "\n",
    "def get_cat_encoded_columns(df: DataFrame, target_name: str) -> List:\n",
    "    \"\"\"Gets all categorical features which are 0-1 encoded.\n",
    "    Parameteres: df (DataFrame), target_name (name of the target column)\n",
    "    Returns: list of names of columns of categorical encoded features\"\"\"\n",
    "    \n",
    "    # Initialize the list\n",
    "    encoded_col = []\n",
    "    # Check if columns values in 0 and 1\n",
    "    for col in df.columns:\n",
    "        if set([0 , 1]).issuperset(df[col].dropna()):\n",
    "            encoded_col.append(col)\n",
    "    # Checks if target column in list      \n",
    "    if target_name in encoded_col:\n",
    "        encoded_col.remove(target_name)\n",
    "    #  Return the list of encoded columns     \n",
    "    return encoded_col\n",
    "\n",
    "def get_num_col(df: DataFrame, encoded_col: List, target_name: str, ordinal_col: List) -> List:\n",
    "    \"\"\"Gets numerical continuous column names from the dataset.\n",
    "    Parameters: df (DataFrame), encoded_col (list of categorical \n",
    "    values encoded to 0-1, target_name (name of target colum),\n",
    "    ordinal_col (list of ordinally encoded variables)\n",
    "    Returns: list of numerical continuous values.\"\"\"\n",
    "    \n",
    "    # Make a list of all numerical values\n",
    "    num_col = df.select_dtypes(exclude='O').columns.to_list()\n",
    "    # Remove encoded categorical columns\n",
    "    num_col = [col for col in num_col if col not in encoded_col]\n",
    "    # Checks if target column in list      \n",
    "    if target_name in num_col:\n",
    "        num_col.remove(target_name)\n",
    "    num_col = [x for x in num_col if x not in ordinal_col]\n",
    "    # Return numerical continuous list\n",
    "    return num_col\n",
    "\n",
    "# ====================STATISTICAL CORRELATIONS CHECK WITH TARGET====================\n",
    "\n",
    "def corr_check_num_cat(df: DataFrame, target_name: str, numerical_col: List) -> List:\n",
    "    \"\"\"Calculates p_value for anova test to check if the numerical variables are correlated\n",
    "    with target. If p_value is less then significance level 0.05 rejcts the null hypothesis \n",
    "    that variables are not correlated. \n",
    "    Paramteres: df (DataFrame), target_name (name of the target column as str), \n",
    "    numerical_col (list of numerical continuous columns).\n",
    "    Returns a list of potentially correlated columns.\"\"\"\n",
    "    \n",
    "    from scipy.stats import f_oneway\n",
    "    \n",
    "    # Go through all variables and append results\n",
    "    p_values = []\n",
    "    for col in numerical_col:\n",
    "        category_group_list = df[[col, target_name]].dropna().groupby(col)[target_name].apply(list)\n",
    "        anova = f_oneway(*category_group_list)\n",
    "        p_values.append(anova[1])\n",
    "    anova_df = pd.DataFrame({'column_name': numerical_col, 'p_value': p_values}).sort_values(by='p_value')\n",
    "    # List of column names where we can reject the null hypothesis \n",
    "    # that the variables are not correlated with each other\n",
    "    corr_col = anova_df[anova_df[\"p_value\"] < 0.05]['column_name'].to_list()\n",
    "    # Prints columns that are correlated with target\n",
    "    print('-'*100)\n",
    "    print(f'The columns that are correlated with target column: {corr_col}')\n",
    "    print('-'*100)\n",
    "    # Return the list of correlated columns\n",
    "    return corr_col\n",
    "\n",
    "def corr_check_cat_cat(df: DataFrame, target_name:str, cat_col: List) -> List:\n",
    "    \"\"\"Performs Chi_Sq test for two categorical variables and finds\n",
    "    the probability of null hypothesis.\n",
    "    H0: The two columns are NOT related to each other\n",
    "    alpha: 0.05\n",
    "    Parameters: df (DataFrame), target_name (name of target column as str),\n",
    "    cat_col (list of all categorical columns)\n",
    "    Returns: a list of potentially correlated columns.\n",
    "    \"\"\"\n",
    "    from scipy.stats import chi2_contingency\n",
    "\n",
    "    # Go through all variables and append results\n",
    "    p_values = []\n",
    "    for col in cat_col:\n",
    "        cross_result = pd.crosstab(index=df[col], columns=df[target_name])\n",
    "        chi_square = chi2_contingency(cross_result)\n",
    "        p_values.append(chi_square[1])\n",
    "    # DataFrame with p_values and names of columns\n",
    "    chi_square_df = pd.DataFrame({'column_name': cat_col, 'p_value': p_values}).sort_values(by='p_value')\n",
    "    # List of column names where we can reject the null hypothesis that the variables are not correlated with each other\n",
    "    corr_col = chi_square_df[chi_square_df[\"p_value\"] < 0.05]['column_name'].to_list()\n",
    "    # Print out the names of columns correlated with target\n",
    "    print('-'*100)\n",
    "    print(f'The columns that are correlated with target column: {corr_col}')\n",
    "    print('-'*100)\n",
    "    # Return correlated columns\n",
    "    return corr_col\n",
    "\n",
    "# ====================CORRELATIONS BETWEEN NUMERICAL FEATURES====================\n",
    "\n",
    "def magnify() -> List:\n",
    "    '''Function that magnifies clicked value in DataFrame.'''\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])]\n",
    "\n",
    "def high_corr_background(cell_value: any) -> str:\n",
    "    '''Assigns background of the cell based on the value. \n",
    "    Highlights highly correlated columns with correlation \n",
    "    higher than 0.7 to red, lower than -0.7 to blue and \n",
    "    1 to green.'''\n",
    "    \n",
    "    # Set the colors\n",
    "    highlight_positive = 'background-color: red'\n",
    "    highlight_negative = 'background-color: blue'\n",
    "    default = 'background-color: white'\n",
    "    onces = 'background-color: green'\n",
    "    \n",
    "    # Conditions\n",
    "    if type(cell_value) in [float, int]:\n",
    "        if (cell_value>=0.7 and cell_value<1.0):\n",
    "            return highlight_positive\n",
    "        elif cell_value <=-0.7:\n",
    "            return highlight_negative\n",
    "        elif cell_value == 1.0:\n",
    "            return onces\n",
    "    return default\n",
    "\n",
    "def pearson_corr_df(df: DataFrame) -> None:\n",
    "    '''Calculates Pearson correlations between numerical features.\n",
    "    Displays styled dataframes for visual clarity of correlations.'''\n",
    "    \n",
    "    for n in range(1, df.shape[1]//10+1):\n",
    "        corr = df.corr().iloc[:, (n-1)*10:n*10]\n",
    "        display(corr.style.applymap(high_corr_background)\\\n",
    "        .format(precision=2)\\\n",
    "        .set_properties(**{'max-width': '60px', 'font-size': '8pt'})\\\n",
    "        .set_caption(\"Pearson correaltions of numerical columns\")\\\n",
    "        .set_table_styles(magnify()))\n",
    "        \n",
    "# ====================TOP CORRELATED FEATURES WITH TARGET====================\n",
    "\n",
    "def target_top_corr(df: DataFrame, target_name: str, columns: List, number_of_corr_col: int=10, numerical: bool=True) -> DataFrame:\n",
    "    '''\n",
    "    Returns DataFrame with top correlated features with the target columns.\n",
    "    Paramteres: df (DataFrame), columns (list of columns to inspect),\n",
    "    target_name (name of target column as str),\n",
    "    num_of_corr_col (number of columns correlated with the target as int),\n",
    "    numerical (if the data is continuous as boolean value)\n",
    "    Returns: DataFrame with most correllated columns.\n",
    "    '''\n",
    "\n",
    "    # Calculating phick, spearman and pearson correlations of continuous variables with target \n",
    "    if numerical: \n",
    "        # Initializing list of values\n",
    "        phik_values = []\n",
    "        spearman_values = []\n",
    "        pearson_values = []\n",
    "        for column in columns:\n",
    "            # Appending values of correlations\n",
    "            df_check = df[[target_name, column]]\n",
    "            phik_values.append(df_check.phik_matrix(interval_cols=[target_name, column]).iloc[0,1])\n",
    "            spearman_values.append(df_check.corr(method='spearman').iloc[0, 1])\n",
    "            pearson_values.append(df_check.corr().iloc[0, 1])\n",
    "        # Building dataframe \n",
    "        top_phik_corr = pd.DataFrame({#'column_name': columns, \n",
    "                                  'phik_correlation' : phik_values,\n",
    "                                  'spearman_correlation': spearman_values,\n",
    "                                 'pearson_correlation': pearson_values}, index=columns)\n",
    "        top_phik_corr = top_phik_corr.sort_values(by = 'phik_correlation', ascending = False)\n",
    "        return top_phik_corr.iloc[:number_of_corr_col]\n",
    "    \n",
    "    # Calculating the phik correlations of categorical variables with target \n",
    "    else:\n",
    "        col = columns + [target_name]\n",
    "        data_for_phik = df[col].astype('object')\n",
    "        phik_matrix = data_for_phik.phik_matrix()\n",
    "        return (phik_matrix[target_name].sort_values(ascending=False).to_frame()\n",
    "                .rename(columns={target_name: 'phik_correlation'}).iloc[1:number_of_corr_col+1])\n",
    "    \n",
    "# ====================PLOTTING CONTINUOUS VARIABLES====================\n",
    "\n",
    "def plot_num(df: DataFrame, target_name: str, num_columns: List, labels: List) -> None:\n",
    "    \"\"\"Plots boxplots and ecdfplot of numerical columns in regards to target column.\n",
    "    Parameteres: df (DataFrame), target_name (name of target column as str),\n",
    "    num_columns (numerical columns for plotting), labels (list of labels)\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the number of rows\n",
    "    rows = len(num_columns)\n",
    "     \n",
    "    # Plot numerical features over target\n",
    "    fig, ax = plt.subplots(rows, 2, figsize=(18, rows*4), tight_layout=True)\n",
    "    fig.suptitle(\"Numerical features vs target\", fontweight=\"bold\", y=1.00, fontsize=14)\n",
    "    x = [0, 1]\n",
    "    for i in range(rows):\n",
    "        for j in range(2):\n",
    "            col = num_columns[i]\n",
    "            if j == 0:\n",
    "                # Plot boxplot\n",
    "                sns.boxplot(data=df[[target_name, col]].dropna(), x=target_name, y=col, ax=ax[i, j])\n",
    "                ax[i, j].set_title(f\"{col} vs {target_name} boxplot\", fontsize=10, fontweight='bold')\n",
    "                ax[i, j].set_xticks(x, labels)\n",
    "                ax[i, j].set_xlabel(\"\")\n",
    "            else:\n",
    "                # Plot kde\n",
    "                sns.kdeplot(data=df[[target_name, col]].dropna(), x=col, hue=target_name, common_norm=False, ax=ax[i, j])\n",
    "                ax[i, j].set_title(f\"{col} vs {target_name} kde \", fontsize=10, fontweight='bold')\n",
    "                ax[i, j].legend(labels[::-1])\n",
    "\n",
    "# ====================PLOTTING CATEGORICAL VARIABLES====================\n",
    "\n",
    "def plot_cat_bars(df: DataFrame, target_name: str, categorical_columns: List) -> None:\n",
    "    \"\"\"Plots bars for all categorical features in dataframe\n",
    "    in relation to target variable as two column subplots.\n",
    "    Paramteres: df (DataFrame), target_name (name of the target column as str),\n",
    "    categorical_columns (list of names of categorical columns\"\"\"\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    # Calculate the number of rows\n",
    "    rows = math.ceil(len(categorical_columns)/2)\n",
    "     \n",
    "    # Plot categories over target\n",
    "    fig, ax = plt.subplots(rows, 2, figsize=(18, rows*4), tight_layout=True)\n",
    "    fig.suptitle(\"Categorical features vs target\", fontweight=\"bold\", y=1.00, fontsize=14)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(2):\n",
    "            if (i*2+j) < len(categorical_columns):\n",
    "                col = categorical_columns[i * 2 + j]\n",
    "                # Perapare data to plot\n",
    "                df_plot = pd.crosstab(df[col], df[target_name]).apply(\n",
    "                    lambda x: round(x / sum(x) * 100, 2), axis=0\n",
    "                )\n",
    "                # Plot data\n",
    "                df_plot.plot(kind=\"bar\", ax=ax[i, j])\n",
    "                # Add bar labels\n",
    "                ax[i, j].bar_label(\n",
    "                    ax[i, j].containers[0],\n",
    "                    fmt=\"%.0f%%\",\n",
    "                    padding=5,\n",
    "                    size=7,\n",
    "                    color=\"black\",\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "                ax[i, j].bar_label(\n",
    "                    ax[i, j].containers[1],\n",
    "                    fmt=\"%.0f%%\",\n",
    "                    padding=4,\n",
    "                    size=7,\n",
    "                    color=\"black\",\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "                ax[i, j].set_yticks([])\n",
    "                ax[i, j].set_xticklabels(ax[i, j].get_xticklabels(), rotation=90, size=8)\n",
    "                ax[i, j].set_xlabel(\"\")\n",
    "                ax[i, j].set_title(f\"{col} vs {target_name}\", fontsize=10, fontweight='bold')\n",
    "                ax[i, j].legend()\n",
    "                ax[i, j].get_legend().remove()\n",
    "                sns.despine(left=True)\n",
    "    # Remove unused axes\n",
    "    if rows*2 != len(categorical_columns):\n",
    "        fig.delaxes(ax[rows-1, 1])\n",
    "    # Add legend\n",
    "    fig.legend(labels=[0, 1], title=target_name, bbox_to_anchor=(1.05, 0.90));\n",
    "    \n",
    "# ====================PLOTTING MISSING VALUES====================\n",
    "\n",
    "def plot_missing(df: DataFrame, df_name: str) -> None:\n",
    "    \"\"\"Plots bar graph with percentages of missing values in the dataframe.\"\"\"\n",
    "\n",
    "    nr_col_nan = (df.isna().sum(axis=0) > 0).sum()\n",
    "    print('-'*100)\n",
    "    print(f\"Number of columns in {df_name}: {df.shape[1]} columns\")\n",
    "    print(f\"Number of columns with missing values in {df_name}: {nr_col_nan} columns\")\n",
    "    print('-'*100)\n",
    "    # Data to plot\n",
    "    plot_data = (df.isnull().mean().reset_index().rename(columns={'index': 'column', 0: 'fraction'})\n",
    "    .sort_values(by='fraction', ascending=False)[:nr_col_nan])\n",
    "    # Plotting the Bar-Plot for NaN percentages \n",
    "    plt.figure(figsize = (20, 8), tight_layout = True)\n",
    "    sns.barplot(x='column', y='fraction', data=plot_data )\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.title(f'Fraction of NaN values in {df_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a1b42-3b7f-49d4-9e73-41bfca72bcc5",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "This process will take a couple of steps for each set of data:\n",
    "\n",
    "1) Loading data using pandas\n",
    "2) Reducing memory usage by custom encoding for each dataset, checking for duplicates and using reduce_memory_usage function\n",
    "3) Splitting data to analyse only train data\n",
    "4) Inspecting distribution of target\n",
    "5) Categorizing columns based on type of data\n",
    "6) EDA of continuous features:\n",
    "* checking significance of correlations with target with anova test, \n",
    "* removing multicollinear features,\n",
    "* checking correlations with target using phik, spearman and pearson correlation\n",
    "* checking for missing values in features with highiest correlations\n",
    "* plotting a number of features with highiest correlations, making conclusions\n",
    "6) EDA of categorical variables: \n",
    "* checking significance of correlations with target with chi-square test, \n",
    "* removing features that are correlated with each other based on spearman correlation,\n",
    "* checking correlations with phik test,\n",
    "* plotting a number of features with highiest correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441556e-ae1a-4a62-ad6f-f69784f4bdcb",
   "metadata": {},
   "source": [
    "## application_train.csv\n",
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a058ba-77cd-4064-9ed3-9c2f18886398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202,500.00</td>\n",
       "      <td>406,597.50</td>\n",
       "      <td>24,700.50</td>\n",
       "      <td>351,000.00</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3,648.00</td>\n",
       "      <td>-2120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1,134.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270,000.00</td>\n",
       "      <td>1,293,502.50</td>\n",
       "      <td>35,698.50</td>\n",
       "      <td>1,129,500.00</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1,186.00</td>\n",
       "      <td>-291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Block</td>\n",
       "      <td>No</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-828.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL   AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0        202,500.00   406,597.50    24,700.50   \n",
       "1               N             0        270,000.00 1,293,502.50    35,698.50   \n",
       "\n",
       "   AMT_GOODS_PRICE NAME_TYPE_SUITE NAME_INCOME_TYPE  \\\n",
       "0       351,000.00   Unaccompanied          Working   \n",
       "1     1,129,500.00          Family    State servant   \n",
       "\n",
       "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
       "0  Secondary / secondary special  Single / not married  House / apartment   \n",
       "1               Higher education               Married  House / apartment   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                        0.02       -9461           -637          -3,648.00   \n",
       "1                        0.00      -16765          -1188          -1,186.00   \n",
       "\n",
       "   DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  \\\n",
       "0            -2120          NaN           1               1                0   \n",
       "1             -291          NaN           1               1                0   \n",
       "\n",
       "   FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
       "0                 1           1           0        Laborers             1.00   \n",
       "1                 1           1           0      Core staff             2.00   \n",
       "\n",
       "   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
       "0                     2                            2   \n",
       "1                     1                            1   \n",
       "\n",
       "  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
       "0                  WEDNESDAY                       10   \n",
       "1                     MONDAY                       11   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "\n",
       "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "\n",
       "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY       ORGANIZATION_TYPE  \\\n",
       "0                       0                        0  Business Entity Type 3   \n",
       "1                       0                        0                  School   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
       "0          0.08          0.26          0.14            0.02              0.04   \n",
       "1          0.31          0.62           NaN            0.10              0.05   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
       "0                         0.97             0.62            0.01   \n",
       "1                         0.99             0.80            0.06   \n",
       "\n",
       "   ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  \\\n",
       "0           0.00           0.07           0.08           0.12          0.04   \n",
       "1           0.08           0.03           0.29           0.33          0.01   \n",
       "\n",
       "   LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  \\\n",
       "0                  0.02            0.02                     0.00   \n",
       "1                  0.08            0.05                     0.00   \n",
       "\n",
       "   NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  \\\n",
       "0               0.00             0.03               0.04   \n",
       "1               0.01             0.09               0.05   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  \\\n",
       "0                          0.97              0.63             0.01   \n",
       "1                          0.99              0.80             0.05   \n",
       "\n",
       "   ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  \\\n",
       "0            0.00            0.07            0.08            0.12   \n",
       "1            0.08            0.03            0.29            0.33   \n",
       "\n",
       "   LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  \\\n",
       "0           0.04                   0.02             0.02   \n",
       "1           0.01                   0.08             0.06   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  \\\n",
       "0                      0.00                0.00             0.03   \n",
       "1                      0.00                0.00             0.10   \n",
       "\n",
       "   BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  \\\n",
       "0               0.04                          0.97              0.62   \n",
       "1               0.05                          0.99              0.80   \n",
       "\n",
       "   COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  \\\n",
       "0             0.01            0.00            0.07            0.08   \n",
       "1             0.06            0.08            0.03            0.29   \n",
       "\n",
       "   FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
       "0            0.12           0.04                   0.02             0.02   \n",
       "1            0.33           0.01                   0.08             0.06   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI FONDKAPREMONT_MODE  \\\n",
       "0                      0.00                0.00   reg oper account   \n",
       "1                      0.00                0.01   reg oper account   \n",
       "\n",
       "   HOUSETYPE_MODE  TOTALAREA_MODE WALLSMATERIAL_MODE EMERGENCYSTATE_MODE  \\\n",
       "0  block of flats            0.01       Stone, brick                  No   \n",
       "1  block of flats            0.07              Block                  No   \n",
       "\n",
       "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0                      2.00                      2.00   \n",
       "1                      1.00                      0.00   \n",
       "\n",
       "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0                      2.00                      2.00               -1,134.00   \n",
       "1                      1.00                      0.00                 -828.00   \n",
       "\n",
       "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "\n",
       "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "\n",
       "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.00                       0.00   \n",
       "1                        0.00                       0.00   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                        0.00                       0.00   \n",
       "1                        0.00                       0.00   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                       0.00                        1.00  \n",
       "1                       0.00                        0.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('application_train.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edc6d1-bdf6-4e53-b18d-acba1f5ca8c9",
   "metadata": {},
   "source": [
    "Let's check the information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa52395-9a52-40cc-b55f-c366c13fb53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 286.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (307511, 122))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info(), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33912b-3219-4225-938a-3a52e850eae1",
   "metadata": {},
   "source": [
    "The application data has 307,511 entries and 122 columns. \n",
    "\n",
    "Let's reduce the space the data takes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283cce9-063c-4a2e-899d-a6af94356cdf",
   "metadata": {},
   "source": [
    "### Reducing memory usage\n",
    "\n",
    "* checking for duplicates\n",
    "* using design function to reduce the datatype\n",
    "* encoding low cardinality categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d651c5c-bc5c-4a5a-85f2-3dc63c8a60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "application_train.csv had 0 rows removed\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates_check(df, 'application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585a82b-b670-459a-8bfa-2914b1026b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function to reduce the memory usage\n",
    "df = reduce_memory_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac2d7e-75d0-4dc1-b35f-bb8e2468d40d",
   "metadata": {},
   "source": [
    "By minimizing the data type we were able to reduce the size of dataframe by more than half.\n",
    "\n",
    "Now let's reduce the data size even further by checking which categorical columns could be encoded to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d76c5-58dc-4095-9203-b107dc7066bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns that are of object type\n",
    "object_col = get_object_columns(df, 'TARGET')\n",
    "\n",
    "for col in object_col:\n",
    "    print(f'{col}: {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8776a-bb6a-4fe9-a138-5b0a570c2179",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* replace 'XNA' with np.nan\n",
    "* reduce the categories in organization type\n",
    "* replace yes, y to 1, replace no, n to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373c64e-5807-4dec-aaa2-7f5bbbb604ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organization_replacer(value: any) -> any:\n",
    "    \"\"\"Reduces the number of unique values \n",
    "    where there are subcategories with ':' sign\"\"\"\n",
    "    \n",
    "    if value not in [np.nan, None]:\n",
    "        x = value.split()[0]\n",
    "        if x[-1] ==\":\":\n",
    "            return x[:-1]\n",
    "    return value\n",
    "\n",
    "def yes_no_replacer(value: str) -> int:\n",
    "    \"\"\"Encodes yes, no columns to 0 and 1\"\"\"\n",
    "    if value is ['Y', 'Yes']:\n",
    "        return 1\n",
    "    elif value in ['N', 'No']:\n",
    "        return 0\n",
    "    \n",
    "# Replace yes no\n",
    "yes_no_col = ['FLAG_OWN_CAR', 'EMERGENCYSTATE_MODE', 'FLAG_OWN_REALTY']\n",
    "for col in yes_no_col :\n",
    "    df[col] = df[col].map(yes_no_replacer)\n",
    "\n",
    "# Replace 'XNA'\n",
    "df.replace({'XNA': np.nan}, inplace=True)\n",
    "\n",
    "# Replace organization\n",
    "df['ORGANIZATION_TYPE'] = df['ORGANIZATION_TYPE'].map(organization_replacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db1de9-615f-4fe9-a0fe-21963b53f7ef",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4269f-bcf8-4704-a596-01ae94d5afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Get features and target\n",
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100, stratify=y)\n",
    "\n",
    "# Get the data for eda\n",
    "df_eda = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "df_eda = df_eda.drop('SK_ID_CURR', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127368d-1471-44e8-8c05-fef4597e7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9431149-f0e3-4f00-ac81-893a0b07cff8",
   "metadata": {},
   "source": [
    "### Plotting distribution of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bf6ac-b9cc-416a-9252-967b5dc1f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot(df_eda, 'TARGET', ['non-defaulters', 'defaulters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8fa977-355e-4495-8142-fc3578670ba9",
   "metadata": {},
   "source": [
    "### Categorizing columns based on type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487613d-571e-44eb-abd2-5570c99171a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns that are of object type\n",
    "object_col = get_object_columns(df_eda, 'TARGET')\n",
    "\n",
    "# Categorical ordinal columns\n",
    "ordinal_col = ['REGION_RATING_CLIENT']\n",
    "\n",
    "# Categorical features that are encoded\n",
    "encoded_col = get_cat_encoded_columns(df_eda, 'TARGET')\n",
    "\n",
    "# All categorical features\n",
    "cat_col = object_col + encoded_col + ordinal_col\n",
    "\n",
    "# Numerical continuous variables\n",
    "num_col = get_num_col(df_eda, encoded_col, 'TARGET', ordinal_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af9aea-215e-497c-828d-b19a03dd9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cat_col) + len(num_col) == df_eda.shape[1] - 1, \"The condition is not true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20631c2c-f7be-4fa7-8003-a5877c761e37",
   "metadata": {},
   "source": [
    "### EDA of continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd39cd2-ec95-4fe5-8e04-4279af229200",
   "metadata": {},
   "source": [
    "#### Checking significance of correlations with target with anova test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde83b1-5a7e-4042-9f08-26a0233e82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting columns that are correlated with target \n",
    "numerical_corr = corr_check_num_cat(df_eda, 'TARGET', num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5bcc6-f236-4e6b-be2a-9e71f3bada46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of numerical columns that are not correlated with target: {len(num_col) - len(numerical_corr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e527fd-3b18-474a-a8ad-0291b6c25a16",
   "metadata": {},
   "source": [
    "#### Inspecting and removing multicollinear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8200d4-1b4d-4ce4-9b65-fbfbc10951c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Pearson correlations between numerical features correlated to target variable\n",
    "df_pearson = df_eda[numerical_corr]\n",
    "pearson_corr_df(df_pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3e1e8-7dbc-4040-8f13-34bdb11d0c45",
   "metadata": {},
   "source": [
    "Looking at the correlations between numerical features we see correlations:\n",
    "1) AMT_GOODS_PRICE - AMT_ANNUITY - AMT_CREDIT\n",
    "2) REGION_RATING_CLIENT_W_CITY - REGION_RATING_CLIENT\n",
    "3) AMT_ANNUITY - AMT_CREDIT\n",
    "4) DEF_30_CNT_SOCIAL_CIRCLE - DEF_60_CNT_SOCIAL_CIRCLE\n",
    "5) FLOORSMAX_MODE - FLOORSMAX_MEDI - FLOORSMIN_MODE - FLOORSMIN_MEDI - FLOORSMAX_AVG - FLOORSMIN_AVG\n",
    "6) FLOORSMAX_MEDI - FLOORSMIN_MODE - FLOORSMIN_MEDI - FLOORSMAX_AVG - FLOORSMIN_AVG\n",
    "7) CNT_CHILDREN - CNT_FAMILY_MEMBERS\n",
    "8) ELEVATORS_MODE - ELEVATORS_MEDI - ELEVATORS_AVG\n",
    "9) FLOORSMIN_MODE - FLOORSMIN_MEDI - FLOORSMIN_AVG - FLOORSMAX_AVG\n",
    "10) ELEVATORS_MEDI - ELEVATORS_AVG\n",
    "11) FLOORSMIN_MEDI - FLOORSMAX_AVG - FLOORSMIN_AVG\n",
    "12) ENTRANCES_MEDI - ENTRANCES_MODE\n",
    "13) FLOORSMAX_AVG - FLOORSMIN_AVG\n",
    "14) YEARS_BEGINEXPLUATATION_MODE - YEARS_BEGINXPLUATATION_MEDI - YEARS_BEGINXPLUATATION_AVG\n",
    "15) YEARS_BUILD_MODE - YEARS_BUILD_MEDI - YEARS_BUILD_AVG\n",
    "16) YEARS_BUILD_MEDI - YEARS_BUILD_AVG\n",
    "17) YEARS_BEGINXPLUATATION_MEDI - YEARS_BEGINXPLUATATION_AVG\n",
    "18) OBS_60_CNT_SOCIAL_CIRCLE - OBS_30_CNT_SOCIAL_CIRCLE\n",
    "\n",
    "\n",
    "As we need to remove multicolinear features we will remove columns: \n",
    "['AMT_GOODS_PRICE', 'REGION_RATING_CLIENT_W_CITY',  'FLOORSMIN_AVG', 'FLOORSMIN_MODE', 'FLOORSMAX_AVG', 'FLOORSMAX_MODE', 'ELEVATORS_MODE', 'ELEVATORS_AVG', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'CNT_FAM_MEMBERS', 'FLOORSMIN_MEDI', 'ENTRANCES_MODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1b7b3-ee78-44e3-b74b-dccf628c3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting names of multicollinear features\n",
    "multicollinear_features = ['AMT_GOODS_PRICE', 'REGION_RATING_CLIENT_W_CITY', 'FLOORSMIN_AVG', 'FLOORSMIN_MODE',\n",
    "                           'FLOORSMAX_AVG', 'FLOORSMAX_MODE', 'ELEVATORS_MODE', 'ELEVATORS_AVG',\n",
    "                           'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'YEARS_BUILD_MODE',\n",
    "                           'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'CNT_FAM_MEMBERS', 'FLOORSMIN_MEDI', 'ENTRANCES_MODE', 'AMT_ANNUITY']\n",
    "\n",
    "# Getting numerical features that are correlated to the target but not with each other\n",
    "numerical = [i for i in numerical_corr if i not in multicollinear_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a862d0-a97b-4143-9cb7-175d108f65e9",
   "metadata": {},
   "source": [
    "#### Checking correlations with target using phik, spearman and pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f1267-7b44-4a7b-9c13-531b9733f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_num = target_top_corr(df_eda, 'TARGET', numerical)\n",
    "df_corr_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d7492-6108-423c-856e-82bcc71ea4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting numbers\n",
    "num_col_plot = df_corr_num.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2052366-74cb-4d21-972c-5cf37311696e",
   "metadata": {},
   "source": [
    "#### Displaying meaning of numerical columns with highiest correlelations to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a156fd-ccb2-493b-9a27-bd47a723ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv(\"HomeCredit_columns_description.csv\", encoding='Latin-1', index_col=0)\n",
    "num_col_plot.append('TARGET')\n",
    "names.loc[(names['Table']=='application_{train|test}.csv')&(names['Row'].isin(num_col_plot))][['Row', 'Description', 'Special']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a015b-0ca3-4217-a41e-7fd8df63a723",
   "metadata": {},
   "source": [
    "#### Checking for missing values in features with highiest correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe6171-566e-46df-a13e-522286c712c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing(df_eda[num_col_plot], 'Missing values in numerical columns with highiest correlation to target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ef46b-1904-4eb9-a95a-1545cf7e13cf",
   "metadata": {},
   "source": [
    "The factions of missing values in features that are correlated to target are more than 0.2 for 4 features. OWN_CAR_AGE and EXT_SOURCE_1 have more than 50% missing values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec31c6b-5bb1-4e6a-a5ad-018418b6f0bd",
   "metadata": {},
   "source": [
    "#### Plotting continuous variables which are correlated with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ece894-1a93-46aa-85a4-b039615f658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num(df_eda, 'TARGET', num_col_plot, ['non-defaulters', 'defaulters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2731b-de0d-4502-b32b-b3ea872eea6a",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Average normalized scores from external data source for defaulters are lower than for non-defaulters by more than 0.1 of normalized values.\n",
    "* Distribution of populations where the client lives shows skewedness toward more populated areas for both defaulters and non-defaulters. Proportionally defaulters live in less populated areas than non-defaulters.\n",
    "* Distribution for both defaulters and non defaulters of amount of credit is skewed toward highier values with the average of 0.5 mln. The tail of distribution for non defaulters is thicker.\n",
    "* As there is more non-defaulters we would expect more observations of defaulted by 60 days past due day from surrounding. One client has 24 people in the surrounding that defaulted in last 60 days in realtion to application. \n",
    "* The average age of owned car is lower for non-defaulters. Some clients have over 60 years old cars.\n",
    "* Standard deviation of median of the maximal number of floors is highier for defaulters.\n",
    "* The distribution of time for defaulters and non-defaulters was comparable.\n",
    "* Non-defaulters had more outliers with high number of children under care.\n",
    "* Distribution of number of elevator has thicker tail for defaulters in comparison with non-defaultes.\n",
    "* In the last year before the application defaulters had more enquiries  to Credit Bureau on average.\n",
    "* Defaulters are on average younger, had their ID replaced later and their last phone changed later than non-defaulters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc5fab-e844-4ca8-a58c-68adf0a76e12",
   "metadata": {},
   "source": [
    "### EDA of categorical variables: \n",
    "* checking significance of correlations with target with chi-square test, \n",
    "* removing features that are correlated with each other based on spearman correlation,\n",
    "* checking correlations with phik test,\n",
    "* plotting a number of features with highiest correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797bec16-8f2a-419c-a47c-a260766300cd",
   "metadata": {},
   "source": [
    "#### Checking significance of correlations with target with chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd2a06-4ba8-483b-a9ca-b135481124ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting categorical features that are correlated to the target\n",
    "categorical = corr_check_cat_cat(df_eda, 'TARGET', cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076fd05-c65d-444a-b27f-1d7d0f175714",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of categorical features that weren't correlated with the target: {len(cat_col) - len(categorical)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca9087-9784-455a-bd96-397e46d0f12c",
   "metadata": {},
   "source": [
    "#### Removing features that are correlated with each other based on Spearman correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89c2a0-48dc-4b6a-80a9-6f5a1b52844f",
   "metadata": {},
   "source": [
    "Now let's check which categorical features can be easily encoded. For this reason we will check the unique values of columns correlated to target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c2dab-14ee-4ed3-ac2e-7d1ed36c6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the correlations between categorical features\n",
    "sns.heatmap(df_eda[categorical].corr(method='spearman'))\n",
    "plt.title(\"Correlations between categorical variables\", fontweight='bold', y=1.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e047e46-3d7e-475c-a6c8-428f3f634994",
   "metadata": {},
   "source": [
    "We can see that some of the features are correlated with each other. Tne columns to consider are: REG_CITY_NOT_WORK_CITY and REG_CITY_NOT_LIVE_CITY. Let's remove the latest from the categorical columns list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb39444-d9ce-4389-9c71-7353f8acc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.remove('REG_CITY_NOT_LIVE_CITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59f6a1-eb78-440a-839a-9b249b4cf26a",
   "metadata": {},
   "source": [
    "#### Checking correlations with phik test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b92aed-a2c2-4ee4-a901-2f51db39ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_cat = target_top_corr(df_eda, 'TARGET', categorical, numerical=False)\n",
    "df_corr_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4af3a-1ee9-47ca-b53e-5007300cfcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_plot = df_corr_cat.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e093d3-e3ca-45d2-bced-29447f033db3",
   "metadata": {},
   "source": [
    "#### Displaying meaning of categorical columns with highiest correlations to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c565be-ec10-43f4-9275-e7ce1a3764d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_plot.append('TARGET')\n",
    "names.loc[(names['Table']=='application_{train|test}.csv')&(names['Row'].isin(cat_col_plot))][['Row', 'Description', 'Special']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ced6c2-f498-4ec9-9a9c-d3701c0e45e6",
   "metadata": {},
   "source": [
    "#### Checking for missing values in features with highiest correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b3ee8-e232-4943-b009-e43159e88e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing(df_eda[cat_col_plot], 'Missing values in categorical columns with highiest correlation to target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1f000-29f9-4347-b8a8-53f081f95fb5",
   "metadata": {},
   "source": [
    "#### Plotting categorical features with highiest correlation vs target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8e8c3-e3dc-4438-aa58-f50d254d27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cat_bars(df_eda, 'TARGET', cat_col_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c74f38-5fb3-4fd2-bbd0-b4b8bc6b6286",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* There are more defaulters among self-employed and business entry type 3. This column may be important in predicting in someone may have problems with credit repayment. \n",
    "* There are more defaulters in occupations like laborers, sales staff, drivers but less in occupations like medicine staff, managers, core staff and high skill tech staff.\n",
    "* People with income from working default more than pensioners, state_servants and commercial associate.\n",
    "* Clients from region with rating 3 default more than from regions with rating 1 and 2.\n",
    "* People with lower level of education default more often.\n",
    "* Fraction of male is highier in defaulting group which may suggest that the probability for defaulting for male is highier. More females take credits.\n",
    "* More defaulters are flagged with permanent address not matching work address at the city level. They may commute to work, not being able to live in a city with highier life expences.\n",
    "* More defaulters gave their employment phone where one of the theories could be their avoidance in contacting them.\n",
    "* Defualters has been flagged more often as the once where permanent address and the city they lived in was different.\n",
    "* More defaulters provided document 3 in comparison with non-defaulters.\n",
    "* Singles and clients in civil marriage defaulted more often than married and widowed. Married were taking the credits most often.\n",
    "* Clients taht live with parents or rent are more prone to default in comparison with people who live in house or appartment. The highiest number of loans were given to people with living in the house.\n",
    "* More people who lived in different city than worked were defaulting although tha majority of people living in the same place were given the credits.\n",
    "* Cash loans were more risky for the bank than revolving loans.\n",
    "* Document 6 was delivered less often by defaulters.\n",
    "* Defaulters provided their phone number less often.\n",
    "* Defaulters had a car less often than non-defaulters. Most clients don't own a car.\n",
    "* People living in accomodation made of wood, stone and brick defaulted more than from other materials.\n",
    "* People who were living unaccompanied were more likely to default. They were also the majority of clients.\n",
    "* Most defaulters didn't own a flat or house."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413de52a-3ffd-45d6-9ec2-693f885b11f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2265381-f663-4a36-8fe7-c9bb95ff29a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
